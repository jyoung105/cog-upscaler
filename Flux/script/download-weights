#!/usr/bin/env python

# Run this before you deploy it on replicate, because if you don't whenever you run the model, 
# it will download the weights from the internet, which will take a long time.

import os
import sys

import torch

from diffusers import StableDiffusionXLPipeline, AutoencoderKL
from huggingface_hub import hf_hub_download, snapshot_download

sys.path.append('.') # append project directory to path so predict.py can be imported

from predict import TOTAL_CACHE, MODEL_ID, MODEL_CACHE, UPSCALER_ID, HYPER_ID, HYPER_FILE


# Set to True for faster uploads and downloads from the Hub using hf_transfer.
# https://huggingface.co/docs/huggingface_hub/package_reference/environment_variables#hfhubenablehftransfer
os.environ["HF_HUB_ENABLE_HF_TRANSFER"]="1"
os.environ["HF_TOKEN"]="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"

# Download model, vae
snapshot_download(repo_id=MODEL_ID, local_dir=MODEL_CACHE)
hf_hub_download(UPSCALER_ID, "config.json", local_dir=TOTAL_CACHE)
hf_hub_download(UPSCALER_ID, "diffusion_pytorch_model.safetensors", local_dir=TOTAL_CACHE)
hf_hub_download(HYPER_ID, HYPER_FILE , local_dir=TOTAL_CACHE)


# vae = AutoencoderKL.from_single_file(
#     f"{TOTAL_CACHE}/sdxl.vae.safetensors", 
#     torch_dtype=torch.float16
# )

# pipe = StableDiffusionXLPipeline.from_single_file(
#     f"{TOTAL_CACHE}/sd_xl_base_1.0.safetensors",
#     vae=vae,
#     # variant="fp16",
#     torch_dtype=torch.float16,
#     use_safetensors=True,
# )


# TODO - we don't need to save all of this and in fact should save just the unet, tokenizer, and config.
# pipe.save_pretrained(MODEL_CACHE, safe_serialization=True, variant="fp16")


# download embedding
# hf_hub_download("jyoung105/general-neg", "ac_neg1.safetensors", local_dir=TOTAL_CACHE)
# hf_hub_download("jyoung105/general-neg", "ac_neg2.safetensors", local_dir=TOTAL_CACHE)


# delete model file to decrease the size of docker image
# if os.path.isfile(f"{TOTAL_CACHE}/sdxl.vae.safetensors"):
#     os.remove(f"{TOTAL_CACHE}/sdxl.vae.safetensors")
    
# if os.path.isfile(f"{TOTAL_CACHE}/sd_xl_base_1.0.safetensors"):
#     os.remove(f"{TOTAL_CACHE}/sd_xl_base_1.0.safetensors")